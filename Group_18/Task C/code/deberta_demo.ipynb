{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Important: Run the code cell below to download the trained model stored in the cloud (GDrive) so that it can be loaded to this environment to make predictions."],"metadata":{"id":"PcmSfj93Aiat"}},{"cell_type":"code","source":["# 1) Install gdown if necessary\n","!pip install gdown\n","\n","# 2) Download your model file from Google Drive\n","!gdown \"https://drive.google.com/uc?id=1RuBncwHrCyTw1ct686zWZWc3e7w6NYX7\" -O best_deberta_bilstm_model.pt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"ntc7cCcpAjyY","executionInfo":{"status":"ok","timestamp":1744176400796,"user_tz":-60,"elapsed":36913,"user":{"displayName":"Minahil Hassan Tariq","userId":"14667589140197322461"}},"outputId":"81e51ef7-9512-40ea-9f49-298a8ccb497b"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.6)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.1.31)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n","Downloading...\n","From (original): https://drive.google.com/uc?id=1RuBncwHrCyTw1ct686zWZWc3e7w6NYX7\n","From (redirected): https://drive.google.com/uc?id=1RuBncwHrCyTw1ct686zWZWc3e7w6NYX7&confirm=t&uuid=9f9dcadf-1af3-4633-b239-56c1cc07fdbe\n","To: /content/best_deberta_bilstm_model.pt\n","100% 750M/750M [00:23<00:00, 32.2MB/s]\n"]}]},{"cell_type":"markdown","source":["## ðŸ§  DeBERTa + Bi-LSTM + Linear Head\n","\n","This notebook demonstrates the evaluation of a **hybrid DeBERTa + BiLSTM model** trained for a **binary Natural Language Inference (NLI)** task.\n","\n","We aim to determine whether a given **hypothesis** is logically entailed by a **premise** using a pretrained transformer backbone (DeBERTa) with an LSTM classifier.\n","\n","This demo performs the following:\n","\n","- Loads and preprocesses the `dev.csv` evaluation dataset.\n","- Uses the DeBERTa tokenizer for encoding inputs.\n","- Defines a custom PyTorch Dataset and DataLoader.\n","- Loads our trained DeBERTa + LSTM model from disk.\n","- Runs inference to predict labels.\n","- Evaluates model performance using accuracy, precision, recall, and F1-score.\n","- Visualizes the confusion matrix.\n","- Saves predictions to `predictions.csv`.\n"],"metadata":{"id":"A9hz6lV402bQ"}},{"cell_type":"code","source":["# 1. Install dependencies (only needed for Colab)\n","!pip install transformers -q\n"],"metadata":{"id":"nz6w9aWioIxB","executionInfo":{"status":"ok","timestamp":1744176459101,"user_tz":-60,"elapsed":2324,"user":{"displayName":"Minahil Hassan Tariq","userId":"14667589140197322461"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# 2. Imports\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import AutoTokenizer, AutoModel\n","import pandas as pd\n","from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n","import matplotlib.pyplot as plt\n"],"metadata":{"id":"jC81O8sLoKRg","executionInfo":{"status":"ok","timestamp":1744176815468,"user_tz":-60,"elapsed":3,"user":{"displayName":"Minahil Hassan Tariq","userId":"14667589140197322461"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# 3. Device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"],"metadata":{"id":"e-v97IGXoNZq","executionInfo":{"status":"ok","timestamp":1744176815501,"user_tz":-60,"elapsed":20,"user":{"displayName":"Minahil Hassan Tariq","userId":"14667589140197322461"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["## Load DeBERTa Tokenizer\n","\n","We initialize the `microsoft/deberta-base` tokenizer for use in encoding premise-hypothesis pairs."],"metadata":{"id":"1sYOCeDpuTPJ"}},{"cell_type":"code","source":["# 4. Tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-base\")\n","\n","def tokenize_premise_hypothesis(premises, hypotheses, max_length=128):\n","    return tokenizer(\n","        premises,\n","        hypotheses,\n","        padding='max_length',\n","        truncation=True,\n","        max_length=max_length,\n","        return_tensors='pt'\n","    )\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rLdzHe6PoO5N","outputId":"95816b77-e4b4-44d4-be7f-6c5479ae6349","collapsed":true,"executionInfo":{"status":"ok","timestamp":1744176816514,"user_tz":-60,"elapsed":1015,"user":{"displayName":"Minahil Hassan Tariq","userId":"14667589140197322461"}}},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:559: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["## Define Custom NLI Dataset\n","\n","We create a custom PyTorch Dataset class that tokenizes each (premise, hypothesis) pair and prepares inputs for the model.\n"],"metadata":{"id":"jUxWUSnuuW6b"}},{"cell_type":"code","source":["# 5. Dataset class\n","class NLIDataset(Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        return {\n","            'input_ids': self.encodings['input_ids'][idx],\n","            'attention_mask': self.encodings['attention_mask'][idx],\n","            'labels': self.labels[idx]\n","        }\n","\n","    def __len__(self):\n","        return len(self.labels)\n"],"metadata":{"id":"rtTQih7hoQO9","executionInfo":{"status":"ok","timestamp":1744176816532,"user_tz":-60,"elapsed":14,"user":{"displayName":"Minahil Hassan Tariq","userId":"14667589140197322461"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["## Define the DeBERTa Model\n","\n","Here we define our hybrid architecture:\n","- The **DeBERTa encoder** provides contextualized embeddings.\n","- A **BiLSTM layer** captures sequential information.\n","- A **linear head** performs classification.\n"],"metadata":{"id":"bPQgZHJSugUM"}},{"cell_type":"code","source":["# 6. Model class\n","class DeBERTaWithBiLSTM(nn.Module):\n","    def __init__(self, hidden_dim=384, dropout=0.3892):\n","        super().__init__()\n","        self.base_model = AutoModel.from_pretrained(\"microsoft/deberta-v3-base\")\n","        self.bilstm = nn.LSTM(768, hidden_dim, num_layers=1, bidirectional=True, batch_first=True)\n","        self.dropout = nn.Dropout(dropout)\n","        self.classifier = nn.Linear(hidden_dim * 2, 2)\n","\n","    def forward(self, input_ids, attention_mask, labels=None):\n","        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask)\n","        sequence_output = outputs.last_hidden_state\n","        lstm_out, _ = self.bilstm(sequence_output)\n","        pooled_output = lstm_out[:, 0]\n","        out = self.dropout(pooled_output)\n","        logits = self.classifier(out)\n","        if labels is not None:\n","            loss_fn = nn.CrossEntropyLoss()\n","            loss = loss_fn(logits, labels)\n","            return {'loss': loss, 'logits': logits}\n","        return {'logits': logits}\n"],"metadata":{"id":"aqw65VLaoR7I","executionInfo":{"status":"ok","timestamp":1744176816538,"user_tz":-60,"elapsed":4,"user":{"displayName":"Minahil Hassan Tariq","userId":"14667589140197322461"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["## Load the Trained Model\n","\n","We load the pretrained weights from disk and move the model to the appropriate device (CPU/GPU). We also set it to evaluation mode.\n"],"metadata":{"id":"1MTNB5Ncve1E"}},{"cell_type":"code","source":["# 8. Load model\n","model = DeBERTaWithBiLSTM().to(device)\n","model.load_state_dict(torch.load(\"best_deberta_bilstm_model.pt\", map_location=device))\n","model.eval()\n","print(\" Model loaded\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fyPdUIShoZcn","outputId":"bdaca0dc-0bf2-49e7-855e-1b707308e172","executionInfo":{"status":"ok","timestamp":1744176818912,"user_tz":-60,"elapsed":2371,"user":{"displayName":"Minahil Hassan Tariq","userId":"14667589140197322461"}}},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":[" Model loaded\n"]}]},{"cell_type":"markdown","source":["## Preprocess test data and Make predictions\n","\n","We pass each batch through the model and collect the predicted labels for performance testing after tokenizing the test data.\n"],"metadata":{"id":"Da9hZIb7uu0y"}},{"cell_type":"code","source":["# Load test data\n","test_df = pd.read_csv(\"test.csv\")  # Make sure 'test.csv' has 'premise' and 'hypothesis' columns\n","\n","# Tokenize premise-hypothesis pairs\n","test_encodings = tokenizer(\n","    test_df['premise'].tolist(),\n","    test_df['hypothesis'].tolist(),\n","    padding='max_length',\n","    truncation=True,\n","    max_length=128,\n","    return_tensors='pt'\n",")\n","\n","# Create test dataset and loader\n","test_dataset = NLIDataset(test_encodings, labels=torch.zeros(len(test_df), dtype=torch.long))\n","test_loader = DataLoader(test_dataset, batch_size=32)\n","\n","# Run model inference\n","test_preds = []\n","\n","model.eval()\n","with torch.no_grad():\n","    for batch in test_loader:\n","        input_ids = batch[\"input_ids\"].to(device)\n","        attention_mask = batch[\"attention_mask\"].to(device)\n","\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","        preds = torch.argmax(outputs[\"logits\"], dim=1)\n","        test_preds.extend(preds.cpu().numpy())\n","\n"],"metadata":{"id":"x-mj30xF8d0o","executionInfo":{"status":"ok","timestamp":1744177055223,"user_tz":-60,"elapsed":31665,"user":{"displayName":"Minahil Hassan Tariq","userId":"14667589140197322461"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["## Save Predictions\n","\n","Finally, we add the modelâ€™s predictions to the original DataFrame and save the results to `predictions.csv`.\n"],"metadata":{"id":"qVqzbuTLvB6J"}},{"cell_type":"code","source":["# Save predictions to CSV for test data (only the 'prediction' column)\n","test_predictions_df = pd.DataFrame({'prediction': test_preds})\n","test_predictions_df.to_csv(\"Group_18_C.csv\", index=False)\n","print(\"test predictions saved!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YJGPnKfcoi3Y","outputId":"a3520ce0-df4e-44e6-acec-b6828a60e634","executionInfo":{"status":"ok","timestamp":1744177055234,"user_tz":-60,"elapsed":6,"user":{"displayName":"Minahil Hassan Tariq","userId":"14667589140197322461"}}},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["test predictions saved!\n"]}]}]}